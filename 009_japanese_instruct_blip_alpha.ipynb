{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPdQsUudXtbMLLlROXzSNEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karaage0703/stable-diffusion-colab-tools/blob/main/009_japanese_instruct_blip_alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Japanese InstructBLIP Alpha\n",
        "\n",
        "## References\n",
        "- https://huggingface.co/stabilityai/japanese-instructblip-alpha\n",
        "- https://ja.stability.ai/blog/japanese-instructblip-alpha\n",
        "- https://note.com/npaka/n/n371e25987267\n",
        "- https://nowokay.hatenablog.com/entry/2023/08/21/124330\n",
        "\n",
        "## Colab Setting\n",
        "- GPU A100 GPU\n",
        "- Hight memory"
      ],
      "metadata": {
        "id": "wLD6rpaiYKqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install library"
      ],
      "metadata": {
        "id": "JKhkhCcop71g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq transformers\n",
        "!pip install -qq einops\n",
        "!pip install -qq bitsandbytes --prefer-binary --extra-index-url=https://jllllll.github.io/bitsandbytes-windows-webui\n",
        "!pip install -qq accelerate\n",
        "!pip install -qq sentencepiece\n",
        "!pip install -qq gradio"
      ],
      "metadata": {
        "id": "KyrVYpdjYQoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import library"
      ],
      "metadata": {
        "id": "ZVNH1epGp_i5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pHToooBYHLV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import LlamaTokenizer, AutoModelForVision2Seq, BlipImageProcessor\n",
        "from PIL import Image\n",
        "import requests\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "Aa45TKsIyqwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model_name = \"stabilityai/japanese-instructblip-alpha\"\n",
        "model = AutoModelForVision2Seq.from_pretrained(model_name,load_in_8bit=True, trust_remote_code=True)\n",
        "processor = BlipImageProcessor.from_pretrained(model_name)\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"novelai/nerdstash-tokenizer-v1\", additional_special_tokens=['▁▁'])\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#model.to(device)\n",
        "print (\"model loaded\")"
      ],
      "metadata": {
        "id": "7OCsL8wRoMlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define helper function to format input prompts"
      ],
      "metadata": {
        "id": "D2rsh_RS09Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to format input prompts\n",
        "def build_prompt(prompt=\"\", sep=\"\\n\\n### \"):\n",
        "    sys_msg = \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\"\n",
        "    p = sys_msg\n",
        "    roles = [\"指示\", \"応答\"]\n",
        "    user_query = \"与えられた画像について、詳細に述べてください。\"\n",
        "    msgs = [\": \\n\" + user_query, \": \"]\n",
        "    if prompt:\n",
        "        roles.insert(1, \"入力\")\n",
        "        msgs.insert(1, \": \\n\" + prompt)\n",
        "    for role, msg in zip(roles, msgs):\n",
        "        p += sep + role + msg\n",
        "    return p"
      ],
      "metadata": {
        "id": "7o7WqbXvVS1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define inference function"
      ],
      "metadata": {
        "id": "geiKyioS1EUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(prompt, image):\n",
        "  #prompt = \"\" # input empty string for image captioning. You can also input questions as prompts\n",
        "  prompt = build_prompt(prompt)\n",
        "  inputs = processor(images=image, return_tensors=\"pt\")\n",
        "  text_encoding = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "  text_encoding[\"qformer_input_ids\"] = text_encoding[\"input_ids\"].clone()\n",
        "  text_encoding[\"qformer_attention_mask\"] = text_encoding[\"attention_mask\"].clone()\n",
        "  inputs.update(text_encoding)\n",
        "\n",
        "  # generate\n",
        "  outputs = model.generate(\n",
        "    **inputs.to(device, dtype=model.dtype),\n",
        "    num_beams=5,\n",
        "    max_new_tokens=32,\n",
        "    min_length=1,\n",
        "#    pad_token_id=tokenizer.pad_token_id,\n",
        "  )\n",
        "  generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
        "  return generated_text"
      ],
      "metadata": {
        "id": "GONeBwxpcIGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch gradio demo"
      ],
      "metadata": {
        "id": "VprHa9cp1GoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"## Japanese InstructBLIP Alpha Demo\")\n",
        "\n",
        "  image = gr.Image(label=\"Intial Image\", type=\"pil\")\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      question = gr.Textbox(lines=3, placeholder=\"質問を\")\n",
        "      submit = gr.Button(\"Submit\", variant=\"primary\")\n",
        "      with gr.Row():\n",
        "        default = gr.Button(\"Default\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "        default.click(lambda: \"画像を説明して\", outputs=question)\n",
        "        clear.click(lambda: \"\", outputs=question)\n",
        "    answer = gr.Textbox(lines=3)\n",
        "    submit.click(infer, inputs=[question, image], outputs=answer)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "jKStm0fRcIOC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}