{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karaage0703/stable-diffusion-colab-tools/blob/main/002_latents_space_walker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-0mHhP4tpTT"
      },
      "source": [
        "# Stable Diffusion Latents Space walker\n",
        "Walk in latents space of Stable Diffusion\n",
        "\n",
        "GitHub repository is below:\n",
        "[stable-diffusion-colab-tools](https://github.com/karaage0703/stable-diffusion-colab-tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jUMAVmhVedQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Hugging Face Login**\n",
        "#@markdown　You need access token of Hugging Face.\n",
        "\n",
        "!pip -qq install git+https://github.com/huggingface/diffusers.git\n",
        "!pip -qq install transformers\n",
        "!pip install -qq tqdm\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Setup**\n",
        "#@markdown　Execute for setup\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=\"fp16\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "3O3bN_cE6LCQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Connect Google Drive**\n",
        "#@markdown　Input output directory and execute for connecting Google Drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir_name = '/content/drive/MyDrive/stable_diffusion/output' #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = Path(save_dir_name) / datetime.now(timezone('Asia/Tokyo')).strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eokgu25DXlQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Generate Image**\n",
        "#@markdown　Enter Parameter  (Attention: Seed=-1 is random)\n",
        "\n",
        "prompt = 'karaage' #@param {type:\"string\"}\n",
        "seed_number = 42 #@param\n",
        "num_inference_steps  = 50 #@param {type:\"slider\", min:1, max:200, step:1}\n",
        "guidance_scale_value = 7.5 #@param {type:\"slider\", min:1, max:20, step:0.1}\n",
        "width_image = 512 #@param {type:\"slider\", min:60, max:640, step:8}\n",
        "height_image = 512 #@param {type:\"slider\", min:60, max:640, step:8}\n",
        "\n",
        "def infer(prompt, seed_number, num_inference_steps, guidance_scale_value, width_image, height_image):\n",
        "    generator = torch.Generator(device=device)\n",
        "    latents = None\n",
        "\n",
        "    # Get a new random seed, store it and use it as the generator state\n",
        "    if seed_number < 0:\n",
        "        seed = generator.seed()\n",
        "    else:\n",
        "        seed = seed_number\n",
        "\n",
        "    generator = generator.manual_seed(seed)\n",
        "\n",
        "    image_latent = torch.randn(\n",
        "        (1, pipe.unet.in_channels, height_image // 8, width_image // 8),\n",
        "        generator = generator,\n",
        "        device = device\n",
        "    )\n",
        "\n",
        "    with torch.autocast('cuda'):\n",
        "        image = pipe(\n",
        "            [prompt],\n",
        "            width=width_image,\n",
        "            height=height_image,\n",
        "            guidance_scale=guidance_scale_value,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            latents = image_latent\n",
        "        )['sample']\n",
        "\n",
        "    return image[0], image_latent\n",
        "\n",
        "def draw_image_from_latents(prompt, num_inference_steps, guidance_scale_value, width_image, height_image, image_latent):\n",
        "    with torch.autocast('cuda'):\n",
        "        image = pipe(\n",
        "            [prompt],\n",
        "            width=width_image,\n",
        "            height=height_image,\n",
        "            guidance_scale=guidance_scale_value,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            latents = image_latent\n",
        "        )['sample']\n",
        "\n",
        "    return image[0]\n",
        "\n",
        "def draw_image(image):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "image, latents = infer(prompt, seed_number, num_inference_steps, guidance_scale_value, width_image, height_image)\n",
        "\n",
        "draw_image(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fI7yVL8w58AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Random walking and save images**\n",
        "#@markdown　Execute for generate images\n",
        "\n",
        "number_frames = 20 #@param\n",
        "max_distance = 0.1 #@param {type:\"slider\", min:0.01, max:0.5, step:0.01}\n",
        "random_walk = np.random.default_rng()\n",
        "save_image = True #@param {type:\"boolean\"}\n",
        "\n",
        "# random walk in latent space\n",
        "image_cv = []\n",
        "\n",
        "for n in tqdm(range(number_frames)):\n",
        "    for i in range(latents.size()[1]):\n",
        "        for j in range(latents.size()[2]):\n",
        "            for k in range(latents.size()[3]):\n",
        "                latents[0][i][j][k] += random_walk.uniform(-max_distance, max_distance)\n",
        "\n",
        "\n",
        "    image = draw_image_from_latents(prompt, num_inference_steps, guidance_scale_value, width_image, height_image, latents)\n",
        "    print('below image is number ' + str(n))\n",
        "    draw_image(image)\n",
        "    file_path = os.path.join(OUTPUT_DIR, 'sd_{}.png'.format(n))\n",
        "    if save_image:\n",
        "        image.save(file_path)\n",
        "    image_cv.append(np.array(image, dtype=np.uint8))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tbKFcowM6huQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Make movie**\n",
        "#@markdown　Set interval time[ms]\n",
        "interval = 500 #@param\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
        "plt.figure(figsize=(image_cv[0].shape[1] / 72.0, image_cv[0].shape[0] / 72.0), dpi = 72)\n",
        "patch = plt.imshow(image_cv[0])\n",
        "plt.axis('off')\n",
        "animate = lambda i: patch.set_data(image_cv[i])\n",
        "ani = matplotlib.animation.FuncAnimation(plt.gcf(), animate, frames=len(image_cv), interval = interval)\n",
        "HTML(ani.to_jshtml())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hkob7kbIYUrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Save movie file**\n",
        "\n",
        "save_filename = 'stable_diffusion_movie' #@param {type:\"string\"}\n",
        "file_movie_path = os.path.join(OUTPUT_DIR, '{}.mp4'.format(save_filename))\n",
        "\n",
        "ani.save(file_movie_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9sDXumJw9S3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "Special Thanks\n",
        "- https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb\n",
        "- https://colab.research.google.com/github/nakamura196/ndl_ocr/blob/main/ndl_ocr_v2.ipynb"
      ],
      "metadata": {
        "id": "8_ieawWDdpjt"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}